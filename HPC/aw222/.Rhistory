remaining_pool = pool - first_event
# Calculate the conditional probability of the second event if the first event does not occur
prob_event_2 = probs[2] / (1 - probs[1])
# Use binomial distribution to determine how many individuals are assigned to the second event
second_event = rbinom(1, remaining_pool, prob_event_2)
# Number of third events
third_event = remaining_pool - second_event
return(c(first_event, second_event, third_event))
}
# Question 27
# state: a vector of population states representing the number of individuals at each life stage
# projection_matrix: a matrix containing the probability of survival and maturity at each life stage
# It returns a new population state vector representing the number of individuals at each life stage after random application of survival and maturity
survival_maturation <- function(state, projection_matrix) { # Initialize the new population state vector with 0
new_state <- rep(0, length(state))
new_additions_to_stage_i <- rep(0, length(state))
# 'for' loop of all life stages except the final stage
for (i in 1:(length(state)-1)) {
# Find the number of individuals in the current stage
current_stage_pop <- state[i]
# Generation of the number of individuals to remain in the current stage and transition to the next stage
N_total <- trinomial(current_stage_pop, c(projection_matrix[i, i], projection_matrix[i+1, i]))
N_stay <- N_total[1]
N_mature <- N_total[2]
new_additions_to_stage_i[i+1]<- N_mature
#    print(new_additions_to_stage_i)
new_state[i] <- N_stay + new_additions_to_stage_i[i]
}
# Generate the number of individuals that survived the final life stage
# add these individuals to the new_state
new_state[length(state)] <- rbinom(1, state[length(state)], projection_matrix[length(state), length(state)]) + new_additions_to_stage_i[length(state)]
return(new_state)
}
# Question 28
random_draw <- function(probability_distribution) {
sample <- runif(1, min = 0, max = 1)
cumulative_distribution <- cumsum(probability_distribution)
# Determine what is the cumulative probability corresponding to the sample
for (i in 1:length(cumulative_distribution)) {
if (sample <= cumulative_distribution[i]) {
return(i)
}
}
}
# Question 29
stochastic_recruitment <- function(projection_matrix, clutch_distribution) {
ncol <- ncol(projection_matrix)
recruitment_rate <- projection_matrix[1, ncol]
clutch_size <- length(clutch_distribution)
# Calculate clutch_size expectations
expected_clutch_size <- sum(clutch_distribution * 1:clutch_size)
# Calculate recruitment_probability
recruitment_probability <- recruitment_rate / expected_clutch_size
return(recruitment_probability)
}
# Question 30
offspring_calc <- function(state, clutch_distribution, recruitment_probability) {
adults <- state[length(state)] # the number of adults
clutches <- rbinom(1, adults, recruitment_probability) # the number of clutches
#  clutches
# initialized offspring
total_offspring <- 0
if (clutches > 0) {
for (i in 1:clutches) {
clutch_size <- random_draw(clutch_distribution) # clutch size from distribution
total_offspring <- total_offspring + clutch_size # add clutch size into total number
}
}
return(total_offspring)
}
# Question 31
stochastic_step <- function(state, projection_matrix, clutch_distribution, recruitment_probability) {
new_state <- survival_maturation(state, projection_matrix)
#  print(new_state)
num_offspring <- offspring_calc(state, clutch_distribution, recruitment_probability)
#  print(num_offspring)
# Calculate the number of offspring
new_state[1] <- new_state[1] + num_offspring
# Add offspring to the first stage
return(new_state)
}
# Question 32
stochastic_simulation <- function(initial_state, projection_matrix, clutch_distribution, simulation_length) {
population_size = rep(0, simulation_length +1) # preallocation
population_size[1] <- sum(initial_state) # Adding the initial state to the population size vector
# Calculate recruitment probability
recruitment_probability <- stochastic_recruitment(projection_matrix, clutch_distribution)
for (i in 1:simulation_length) {
#  If the population size is 0, the simulation stops
if (population_size[i] == 0) {
return(population_size)
}
# Randomly sampling
new_state <- stochastic_step(initial_state, projection_matrix, clutch_distribution, recruitment_probability)
initial_state <- new_state
# state <- population_size[i] #??
population_size[i+1] <- sum(new_state)
# Adding a new state to the population size vector
}
return(population_size)
}
# Question 33
question_33 <- function() {
simulation_length <- 24
clutch_distribution <- c(0.06,0.08,0.13,0.15,0.16,0.18,0.15,0.06,0.03)
projection_matrix <- matrix(c(0.1, 0.6, 0.0, 0.0,
0.0, 0.4, 0.4, 0.0,
0.0, 0.0, 0.7, 0.25,
2.6, 0.0, 0.0, 0.4),nrow=4,ncol=4)
initial_state_1 <- c(0, 0, 0, 100)
initial_state_2 <- c(25, 25, 25, 25)
population_size_1 <- stochastic_simulation(initial_state_1, projection_matrix, clutch_distribution, simulation_length)
population_size_2 <- stochastic_simulation(initial_state_2, projection_matrix, clutch_distribution, simulation_length)
# Plot
png(filename="question_33.png", width = 600, height = 400)
plot(1:length(population_size_1), population_size_1, type = "l", col = "red", xlab = "Time", ylab = "Population Size",ylim = c(0, 1000))
lines(1:length(population_size_2), population_size_2, col = "blue")
legend("topright", c("Initial conditions with 100 adults in four stages", "Initial conditions with evenly spread population in four stages"), col=c("red", "blue"), lwd=1)
Sys.sleep(0.1)
dev.off()
return("The earlier deterministic simulations were smooth, while the stochastic simulations are more jagged.
This is because the deterministic simulations assumed a fixed number of clutches each time step,
while the stochastic simulations randomly selected the number of clutches from a given distribution.")
}
# Question 36
question_36 <- function(){
extinct_250 <- 0
extinct_500 <- 0
extinct_750 <- 0
extinct_1000 <- 0
files <- list.files(pattern = "stochastic_model_HPC_results_*")
for(i in 1:length(files)){
load(files[i])
# load each file one by one
#分别计算各个种群有多少灭绝
if(i <= 250){
if(tail(results, n = 1) == 0) {
extinct_250 <- extinct_250 + 1
}
}
else if (i <= 500){
if(tail(results, n = 1) == 0) {
extinct_500 <- extinct_500 + 1
}
}
else if (i <= 750){
if(tail(results, n = 1) == 0) {
extinct_750 <- extinct_750 + 1
}
}
else{
if(tail(results, n = 1) == 0) {
extinct_1000 <- extinct_1000 + 1
}
}
}
extinct_250 <- extinct_250 / 250
extinct_500 <- extinct_500 / 250
extinct_750 <- extinct_750 / 250
extinct_1000 <- extinct_1000 / 250
png(filename="question_36.png", width = 600, height = 400)
# plot your graph here
barplot(c(extinct_250, extinct_500, extinct_750, extinct_1000),
xlab = "Initial Condition", ylab = "Proportion of Populations Extinct",
names.arg = c("1large population","2small population", "3large population spread", "4small population spread"))
Sys.sleep(0.1)
dev.off()
return("A small population spread across the life stages are the most likely to extinct, then comes to a samll population of 10 adults.
Overall a small population shown a more likely to extinct, both evenly spread or adults large population are stable to exist.
This may because the small population would produce less offsprings, stage by stage, they are more likely to be extinct.")
}
question_36()
# Question 37
question_37 <- function(){
files <- list.files(pattern = "stochastic_model_HPC_results_*")
load(files[1])
total_population_size_large <- data.frame(rep(NA,length(results)))
total_population_size_small <- data.frame(rep(NA,length(results)))
# For initial condition with a large population spread across the life stage
for(i in 501:750){
load(files[i])
# Calculate the total population size for each
total_population_size_large <- data.frame(total_population_size_large,results)
}
# For initial condition with a small population spread across the life stages
for(i in 751:1000){
load(files[i])
# Calculate the total population size for each
total_population_size_small <- data.frame(total_population_size_small,results)
}
total_population_size_large <- total_population_size_large[, -1]
total_population_size_small <- total_population_size_small[, -1]
# Calculate the population trend
population_trend_large <- apply(total_population_size_large, 1, mean)
population_trend_small <- apply(total_population_size_small, 1, mean)
# Set the simulation length and projection matrix
simulation_length <- 24
projection_matrix <- matrix(c(0.1, 0.6, 0.0, 0.0,
0.0, 0.4, 0.4, 0.0,
0.0, 0.0, 0.7, 0.25,
2.6, 0.0, 0.0, 0.4),nrow=4,ncol=4)
# Set the initial conditions
initial_state_3 <- state_initialise_spread(initial_size=100,num_stages=4)
initial_state_4 <- state_initialise_spread(initial_size=10,num_stages=4)
# The deterministic population size
large_size_deterministic <- deterministic_simulation(initial_state_3, projection_matrix, simulation_length)
small_size_deterministic <- deterministic_simulation(initial_state_4, projection_matrix, simulation_length)
# Plot
png(filename="question_37_small.png", width = 600, height = 400)
plot(small_size_deterministic, type = "l", col = "red", ylim = c(0, 200),
xlab = "Time step", ylab = "Population size", main = "Small mixed population")
lines(population_trend_small, col = "blue")
legend("topright", c("small stochastic trend", "small deterministic model"), lty = 1, col = c("red", "blue"))
Sys.sleep(0.1)
dev.off()
png(filename="question_37_large.png", width = 600, height = 400)
plot(large_size_deterministic, type = "l", col = "red", ylim = c(0, 600),
xlab = "Time step", ylab = "Population size", main = "Large mixed population")
lines(population_trend_large, col = "blue")
legend("topright", c("large stochastic trend", "large deterministic model"), lty = 1, col = c("red", "blue"))
Sys.sleep(0.1)
dev.off()
return("Depends on the time step, the smaller the time step, the results is more appropriate.
As in the early stage, both small and large population with evenly spread shown nearly lapped expected and deterministic trend lines.
However, as the time step change, there are differences but still follows at the similar increasing trends.
This might because of the recruitment and clutch probability used in this deterministic is the most idea expected, although took the randomly sampling into count, there is still the 'idea' condition.
The real situation trends may change faster. ")
}
question_37()
# Question 37
question_37 <- function(){
files <- list.files(pattern = "stochastic_model_HPC_results_*")
load(files[1])
total_population_size_large <- data.frame(rep(NA,length(results)))
total_population_size_small <- data.frame(rep(NA,length(results)))
# For initial condition with a large population spread across the life stage
for(i in 501:750){
load(files[i])
# Calculate the total population size for each
total_population_size_large <- data.frame(total_population_size_large,results)
}
# For initial condition with a small population spread across the life stages
for(i in 751:1000){
load(files[i])
# Calculate the total population size for each
total_population_size_small <- data.frame(total_population_size_small,results)
}
total_population_size_large <- total_population_size_large[, -1]
total_population_size_small <- total_population_size_small[, -1]
# Calculate the population trend
population_trend_large <- apply(total_population_size_large, 1, mean)
population_trend_small <- apply(total_population_size_small, 1, mean)
# Set the simulation length and projection matrix
simulation_length <- 24
projection_matrix <- matrix(c(0.1, 0.6, 0.0, 0.0,
0.0, 0.4, 0.4, 0.0,
0.0, 0.0, 0.7, 0.25,
2.6, 0.0, 0.0, 0.4),nrow=4,ncol=4)
# Set the initial conditions
initial_state_3 <- state_initialise_spread(initial_size=100,num_stages=4)
initial_state_4 <- state_initialise_spread(initial_size=10,num_stages=4)
# The deterministic population size
large_size_deterministic <- deterministic_simulation(initial_state_3, projection_matrix, simulation_length)
small_size_deterministic <- deterministic_simulation(initial_state_4, projection_matrix, simulation_length)
# Plot
png(filename="question_37_small.png", width = 600, height = 400)
plot(small_size_deterministic, type = "l", col = "red", ylim = c(0, 200),
xlab = "Time step", ylab = "Population size", main = "Small mixed population")
lines(population_trend_small, col = "blue")
legend("topright", c("small stochastic trend", "small deterministic model"), lty = 1, col = c("red", "blue"))
Sys.sleep(0.1)
dev.off()
png(filename="question_37_large.png", width = 600, height = 400)
plot(large_size_deterministic, type = "l", col = "red", ylim = c(0, 600),
xlab = "Time step", ylab = "Population size", main = "Large mixed population")
lines(population_trend_large, col = "blue")
legend("topright", c("large stochastic trend", "large deterministic model"), lty = 1, col = c("red", "blue"))
Sys.sleep(0.1)
dev.off()
return("Depends on the population size, the large mixed population shows a more appropriate simulation.
As in the large mixed population, the expected and deterministic trend lines nearly lapped.
However, in the small mixed population, there are differences but still follows at the similar increasing trends.
This might because of the recruitment and clutch probability used in this deterministic is the most idea expected, although took the randomly sampling into count, there is still the 'idea' condition.
Therefore, in a small mixed population, shows obvious.")
}
question_37()
# Challenge question F
Challenge_F <- function() {
files <- list.files(pattern = "stochastic_model_HPC_results_*")
simulation_number <- c()
initial_condition <- c()
time_step <- c()
population_size <- c()
population_size_df <- data.frame(simulation_number, initial_condition, time_step, population_size,
stringsAsFactors = FALSE)
population_size_df1 <- data.frame(simulation_number, initial_condition, time_step, population_size,
stringsAsFactors = FALSE)
population_size_df2 <- data.frame(simulation_number, initial_condition, time_step, population_size,
stringsAsFactors = FALSE)
population_size_df3 <- data.frame(simulation_number, initial_condition, time_step, population_size,
stringsAsFactors = FALSE)
population_size_df4 <- data.frame(simulation_number, initial_condition, time_step, population_size,
stringsAsFactors = FALSE)
# Generate all data frames
for(i in 1:length(files)){
load(files[i])
# Calculate each survival condition separately
if(i <= 250){
for(j in 1:length(results)){
population_size_df[j,1] <- i  # Fill simulation_number
population_size_df[j,2] <- "small adult"  # Fill initial_condition
population_size_df[j,3] <- j-1  # Fill time_step
population_size_df[j,4] <- results[j] # Fill population_size
}
population_size_df1 <- rbind(population_size_df1,population_size_df)
}
else if (i <= 500){
for(j in 1:length(results)){
population_size_df[j,1] <- i  # Fill simulation_number
population_size_df[j,2] <- "large adult"  # FIll initial_condition
population_size_df[j,3] <- j-1  # Fill time_step
population_size_df[j,4] <- results[j] # Fill population_size
}
population_size_df2 <- rbind(population_size_df2,population_size_df)
}
else if (i <= 750){
for(j in 1:length(results)){
population_size_df[j,1] <- i  # Fill simulation_number
population_size_df[j,2] <- "small evenly spread"  # Fill initial_condition
population_size_df[j,3] <- j-1  # Fill time_step
population_size_df[j,4] <- results[j] # Fill population_size
}
population_size_df3 <- rbind(population_size_df3,population_size_df)
}
else{
for(j in 1:length(results)){
population_size_df[j,1] <- i  # Fill simulation_number
population_size_df[j,2] <- "large evenly spread "  # Fill initial_condition
population_size_df[j,3] <- j-1  # Fill time_step
population_size_df[j,4] <- results[j] # Fill population_size
}
population_size_df4 <- rbind(population_size_df4,population_size_df)
}
}
# Aggregate the results of all four simulations into population_size_df
population_size_df <- data.frame()
population_size_df <- rbind(population_size_df1,population_size_df2,population_size_df3,population_size_df4)
colnames(population_size_df) <- c("simulation_number", "initial_condition", "time_step", "population_size")
# Plot
library(ggplot2)
ggplot(data = population_size_df, aes(x = time_step, y = population_size, group = simulation_number,
colour = initial_condition)) +
geom_line(alpha = 0.1) +
xlab("Time step") +
ylab("Population size") +
ggtitle("Population size time series for all simulations")
ggsave("Challenge_F.png")
}
Challenge_F()
# Question 37
question_37 <- function(){
files <- list.files(pattern = "stochastic_model_HPC_results_*")
load(files[1])
total_population_size_large <- data.frame(rep(NA,length(results)))
total_population_size_small <- data.frame(rep(NA,length(results)))
# For initial condition with a large population spread across the life stage
for(i in 501:750){
load(files[i])
# Calculate the total population size for each
total_population_size_large <- data.frame(total_population_size_large,results)
}
# For initial condition with a small population spread across the life stages
for(i in 751:1000){
load(files[i])
# Calculate the total population size for each
total_population_size_small <- data.frame(total_population_size_small,results)
}
total_population_size_large <- total_population_size_large[, -1]
total_population_size_small <- total_population_size_small[, -1]
# Calculate the population trend
population_trend_large <- apply(total_population_size_large, 1, mean)
population_trend_small <- apply(total_population_size_small, 1, mean)
# Set the simulation length and projection matrix
simulation_length <- 24
projection_matrix <- matrix(c(0.1, 0.6, 0.0, 0.0,
0.0, 0.4, 0.4, 0.0,
0.0, 0.0, 0.7, 0.25,
2.6, 0.0, 0.0, 0.4),nrow=4,ncol=4)
# Set the initial conditions
initial_state_3 <- state_initialise_spread(initial_size=100,num_stages=4)
initial_state_4 <- state_initialise_spread(initial_size=10,num_stages=4)
# The deterministic population size
large_size_deterministic <- deterministic_simulation(initial_state_3, projection_matrix, simulation_length)
small_size_deterministic <- deterministic_simulation(initial_state_4, projection_matrix, simulation_length)
# Plot
png(filename="question_37_small.png", width = 600, height = 400)
plot(small_size_deterministic, type = "l", col = "red", ylim = c(0, 200),
xlab = "Time step", ylab = "Population size", main = "Small evenly spread population")
lines(population_trend_small, col = "blue")
legend("topright", c("small stochastic trend", "small deterministic model"), lty = 1, col = c("red", "blue"))
Sys.sleep(0.1)
dev.off()
png(filename="question_37_large.png", width = 600, height = 400)
plot(large_size_deterministic, type = "l", col = "red", ylim = c(0, 600),
xlab = "Time step", ylab = "Population size", main = "Large evenly spread population")
lines(population_trend_large, col = "blue")
legend("topright", c("large stochastic trend", "large deterministic model"), lty = 1, col = c("red", "blue"))
Sys.sleep(0.1)
dev.off()
return("Depends on the population size, the large evenly spread population shows a more appropriate simulation.
As in the large evenly spread population, the expected and deterministic trend lines nearly lapped.
However, in the small evenly spread population, there are differences but still follows at the similar increasing trends.
This might because of the recruitment and clutch probability used in this deterministic is the most idea expected, although took the randomly sampling into count, there is still the 'idea' condition.
Therefore, in a small evenly spread population, shows obvious.")
}
question_37()
# Question 36
question_36 <- function(){
extinct_250 <- 0
extinct_500 <- 0
extinct_750 <- 0
extinct_1000 <- 0
files <- list.files(pattern = "stochastic_model_HPC_results_*")
for(i in 1:length(files)){
load(files[i])
# load each file one by one
#分别计算各个种群有多少灭绝
if(i <= 250){
if(tail(results, n = 1) == 0) {
extinct_250 <- extinct_250 + 1
}
}
else if (i <= 500){
if(tail(results, n = 1) == 0) {
extinct_500 <- extinct_500 + 1
}
}
else if (i <= 750){
if(tail(results, n = 1) == 0) {
extinct_750 <- extinct_750 + 1
}
}
else{
if(tail(results, n = 1) == 0) {
extinct_1000 <- extinct_1000 + 1
}
}
}
extinct_250 <- extinct_250 / 250
extinct_500 <- extinct_500 / 250
extinct_750 <- extinct_750 / 250
extinct_1000 <- extinct_1000 / 250
png(filename="question_36.png", width = 600, height = 400)
# plot your graph here
barplot(c(extinct_250, extinct_500, extinct_750, extinct_1000),
xlab = "Initial Condition", ylab = "Proportion of Populations Extinct",
names.arg = c("large adults population","small adult population", "large population spread", "small population spread"))
Sys.sleep(0.1)
dev.off()
return("A small population spread across the life stages are the most likely to extinct, then comes to a large population of 100 adults.
Overall a small population shows a more likely to extinct, both evenly spread or adults large population have relatively lower extinct rate.
This may because the small population would produce less offsprings, stage by stage, they are more likely to be extinct.")
}
question_36()
# Question 36
question_36 <- function(){
extinct_250 <- 0
extinct_500 <- 0
extinct_750 <- 0
extinct_1000 <- 0
files <- list.files(pattern = "stochastic_model_HPC_results_*")
for(i in 1:length(files)){
load(files[i])
# load each file one by one
#分别计算各个种群有多少灭绝
if(i <= 250){
if(tail(results, n = 1) == 0) {
extinct_250 <- extinct_250 + 1
}
}
else if (i <= 500){
if(tail(results, n = 1) == 0) {
extinct_500 <- extinct_500 + 1
}
}
else if (i <= 750){
if(tail(results, n = 1) == 0) {
extinct_750 <- extinct_750 + 1
}
}
else{
if(tail(results, n = 1) == 0) {
extinct_1000 <- extinct_1000 + 1
}
}
}
extinct_250 <- extinct_250 / 250
extinct_500 <- extinct_500 / 250
extinct_750 <- extinct_750 / 250
extinct_1000 <- extinct_1000 / 250
png(filename="question_36.png", width = 600, height = 400)
# plot your graph here
barplot(c(extinct_250, extinct_500, extinct_750, extinct_1000),
xlab = "Initial Condition", ylab = "Proportion of Populations Extinct",
names.arg = c("large adults P","small adult P", "large spread P", "small spread P"))
Sys.sleep(0.1)
dev.off()
return("A small population spread across the life stages are the most likely to extinct, then comes to a large population of 100 adults.
Overall a small population shows a more likely to extinct, both evenly spread or adults large population have relatively lower extinct rate.
This may because the small population would produce less offsprings, stage by stage, they are more likely to be extinct.")
}
question_36()
